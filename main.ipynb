{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "usage: ipykernel_launcher.py [-h] [-s SETUP] -d DATA [-hparams HYPERPARAMS]\n",
      "                             [-e EPOCHS] [-lr LEARNING_RATE] [-bs BATCH_SIZE]\n",
      "                             [-t TRAIN]\n",
      "ipykernel_launcher.py: error: the following arguments are required: -d/--data\n"
     ]
    },
    {
     "ename": "SystemExit",
     "evalue": "2",
     "output_type": "error",
     "traceback": [
      "An exception has occurred, use %tb to see the full traceback.\n",
      "\u001b[1;31mSystemExit\u001b[0m\u001b[1;31m:\u001b[0m 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\IPython\\core\\interactiveshell.py:3426: UserWarning: To exit: use 'exit', 'quit', or Ctrl-D.\n",
      "  warn(\"To exit: use 'exit', 'quit', or Ctrl-D.\", stacklevel=1)\n"
     ]
    }
   ],
   "source": [
    "from __future__ import print_function\n",
    "import argparse\n",
    "import numpy  as np\n",
    "from PIL import Image\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torchvision\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "from torch.utils.data.sampler import SubsetRandomSampler\n",
    "from torchvision import transforms\n",
    "\n",
    "from data_loaders import Plain_Dataset, eval_data_dataloader\n",
    "from deep_emotion import Deep_Emotion\n",
    "from generate_data import Generate_data\n",
    "\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "def Train(epochs,train_loader,val_loader,criterion,optmizer,device):\n",
    "    '''\n",
    "    Training Loop\n",
    "    '''\n",
    "    print(\"===================================Start Training===================================\")\n",
    "    for e in range(epochs):\n",
    "        train_loss = 0\n",
    "        validation_loss = 0\n",
    "        train_correct = 0\n",
    "        val_correct = 0\n",
    "        # Train the model  #\n",
    "        net.train()\n",
    "        for data, labels in train_loader:\n",
    "            data, labels = data.to(device), labels.to(device)\n",
    "            optmizer.zero_grad()\n",
    "            outputs = net(data)\n",
    "            loss = criterion(outputs,labels)\n",
    "            loss.backward()\n",
    "            optmizer.step()\n",
    "            train_loss += loss.item()\n",
    "            _, preds = torch.max(outputs,1)\n",
    "            train_correct += torch.sum(preds == labels.data)\n",
    "\n",
    "        #validate the model#\n",
    "        net.eval()\n",
    "        for data,labels in val_loader:\n",
    "            data, labels = data.to(device), labels.to(device)\n",
    "            val_outputs = net(data)\n",
    "            val_loss = criterion(val_outputs, labels)\n",
    "            validation_loss += val_loss.item()\n",
    "            _, val_preds = torch.max(val_outputs,1)\n",
    "            val_correct += torch.sum(val_preds == labels.data)\n",
    "\n",
    "        train_loss = train_loss/len(train_dataset)\n",
    "        train_acc = train_correct.double() / len(train_dataset)\n",
    "        validation_loss =  validation_loss / len(validation_dataset)\n",
    "        val_acc = val_correct.double() / len(validation_dataset)\n",
    "        print('Epoch: {} \\tTraining Loss: {:.8f} \\tValidation Loss {:.8f} \\tTraining Acuuarcy {:.3f}% \\tValidation Acuuarcy {:.3f}%'\n",
    "                                                           .format(e+1, train_loss,validation_loss,train_acc * 100, val_acc*100))\n",
    "\n",
    "    torch.save(net.state_dict(),'deep_emotion-{}-{}-{}.pt'.format(epochs,batchsize,lr))\n",
    "    print(\"===================================Training Finished===================================\")\n",
    "\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    parser = argparse.ArgumentParser(description=\"Configuration of setup and training process\")\n",
    "    parser.add_argument('-s', '--setup', type=bool, help='setup the dataset for the first time')\n",
    "    parser.add_argument('-d', '--data', type=str,required= True,\n",
    "                               help='data folder that contains data files that downloaded from kaggle (train.csv and test.csv)')\n",
    "    parser.add_argument('-hparams', '--hyperparams', type=bool,\n",
    "                               help='True when changing the hyperparameters e.g (batch size, LR, num. of epochs)')\n",
    "    parser.add_argument('-e', '--epochs', type= int, help= 'number of epochs')\n",
    "    parser.add_argument('-lr', '--learning_rate', type= float, help= 'value of learning rate')\n",
    "    parser.add_argument('-bs', '--batch_size', type= int, help= 'training/validation batch size')\n",
    "    parser.add_argument('-t', '--train', type=bool, help='True when training')\n",
    "    args = parser.parse_args()\n",
    "\n",
    "    if args.setup :\n",
    "        generate_dataset = Generate_data(args.data)\n",
    "        generate_dataset.split_test()\n",
    "        generate_dataset.save_images()\n",
    "        generate_dataset.save_images('finaltest')\n",
    "        generate_dataset.save_images('val')\n",
    "\n",
    "    if args.hyperparams:\n",
    "        epochs = args.epochs\n",
    "        lr = args.learning_rate\n",
    "        batchsize = args.batch_size\n",
    "    else :\n",
    "        epochs = 100\n",
    "        lr = 0.005\n",
    "        batchsize = 128\n",
    "\n",
    "    if args.train:\n",
    "        net = Deep_Emotion()\n",
    "        net.to(device)\n",
    "        print(\"Model archticture: \", net)\n",
    "        traincsv_file = args.data+'/'+'train.csv'\n",
    "        validationcsv_file = args.data+'/'+'val.csv'\n",
    "        train_img_dir = args.data+'/'+'train/'\n",
    "        validation_img_dir = args.data+'/'+'val/'\n",
    "\n",
    "        transformation= transforms.Compose([transforms.ToTensor(),transforms.Normalize((0.5,),(0.5,))])\n",
    "        train_dataset= Plain_Dataset(csv_file=traincsv_file, img_dir = train_img_dir, datatype = 'train', transform = transformation)\n",
    "        validation_dataset= Plain_Dataset(csv_file=validationcsv_file, img_dir = validation_img_dir, datatype = 'val', transform = transformation)\n",
    "        train_loader= DataLoader(train_dataset,batch_size=batchsize,shuffle = True,num_workers=0)\n",
    "        val_loader=   DataLoader(validation_dataset,batch_size=batchsize,shuffle = True,num_workers=0)\n",
    "\n",
    "        criterion= nn.CrossEntropyLoss()\n",
    "        optmizer= optim.Adam(net.parameters(),lr= lr)\n",
    "        Train(epochs, train_loader, val_loader, criterion, optmizer, device)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
