{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import print_function\n",
    "import argparse\n",
    "import os\n",
    "import cv2\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torch\n",
    "from torchvision import transforms\n",
    "from PIL import Image\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "import torch.nn.functional as F\n",
    "from deep_emotion import Deep_Emotion\n",
    "from data_loaders import Plain_Dataset, eval_data_dataloader\n",
    "\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "parser = argparse.ArgumentParser(description=\"Configuration of testing process\")\n",
    "parser.add_argument('-d', '--data', type=str,required = True, help='Folder that contains the finaltest.csv and test images')\n",
    "parser.add_argument('-m', '--model', type=str,required = True, help='Path to pretrained model')\n",
    "parser.add_argument('-t', '--test_acc', type=bool, help='Only show test accuarcy')\n",
    "parser.add_argument('-c', '--cam', type=bool, help='Test the model in real time with webcam connect via usb')\n",
    "args = parser.parse_args()\n",
    "\n",
    "transformation = transforms.Compose([transforms.ToTensor(),transforms.Normalize((0.5,),(0.5,))])\n",
    "dataset = Plain_Dataset(csv_file=args.data+'/finaltest.csv',img_dir = args.data+'/'+'finaltest/',datatype = 'finaltest',transform = transformation)\n",
    "test_loader =  DataLoader(dataset,batch_size=64,num_workers=0)\n",
    "\n",
    "net = Deep_Emotion()\n",
    "print(\"Deep Emotion:-\", net)\n",
    "net.load_state_dict(torch.load(args.model))\n",
    "net.to(device)\n",
    "net.eval()\n",
    "#Model Evaluation on test data\n",
    "classes = ('Angry', 'Disgust', 'Fear', 'Happy','Sad', 'Surprise', 'Neutral')\n",
    "total = []\n",
    "if args.test_acc:\n",
    "    with torch.no_grad():\n",
    "        for data, labels in test_loader:\n",
    "            data, labels = data.to(device), labels.to(device)\n",
    "            outputs = net(data)\n",
    "            pred = F.softmax(outputs,dim=1)\n",
    "            classs = torch.argmax(pred,1)\n",
    "            wrong = torch.where(classs != labels,torch.tensor([1.]).cuda(),torch.tensor([0.]).cuda())\n",
    "            acc = 1- (torch.sum(wrong) / 64)\n",
    "            total.append(acc.item())\n",
    "\n",
    "    print('Accuracy of the network on the test images: %d %%' % (100 * np.mean(total)))\n",
    "\n",
    "\n",
    "#helper_function for real time testing\n",
    "def load_img(path):\n",
    "    img = Image.open(path)\n",
    "    img = transformation(img).float()\n",
    "    img = torch.autograd.Variable(img,requires_grad = True)\n",
    "    img = img.unsqueeze(0)\n",
    "    return img.to(device)\n",
    "\n",
    "if args.cam:\n",
    "    # Load the cascade\n",
    "    face_cascade = cv2.CascadeClassifier('cascade_model/haarcascade_frontalface_default.xml')\n",
    "\n",
    "    # To capture video from webcam.\n",
    "    cap = cv2.VideoCapture(0)\n",
    "    while True:\n",
    "        # Read the frame\n",
    "        _, img = cap.read()\n",
    "        # Convert to grayscale\n",
    "        gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "        # Detect the faces\n",
    "        faces = face_cascade.detectMultiScale(gray, 1.1, 4)\n",
    "        # Draw the rectangle around each face\n",
    "        for (x, y, w, h) in faces:\n",
    "            roi = img[y:y+h, x:x+w]\n",
    "            roi = cv2.cvtColor(roi,cv2.COLOR_BGR2GRAY)\n",
    "            roi = cv2.resize(roi,(48,48))\n",
    "            cv2.imwrite(\"roi.jpg\", roi)\n",
    "            cv2.rectangle(img, (x, y), (x+w, y+h), (255, 0, 0), 2)\n",
    "\n",
    "        imgg = load_img(\"roi.jpg\")\n",
    "        out = net(imgg)\n",
    "        pred = F.softmax(out)\n",
    "        classs = torch.argmax(pred,1)\n",
    "        wrong = torch.where(classs != 3,torch.tensor([1.]).cuda(),torch.tensor([0.]).cuda())\n",
    "        classs = torch.argmax(pred,1)\n",
    "        prediction = classes[classs.item()]\n",
    "\n",
    "        font = cv2.FONT_HERSHEY_SIMPLEX\n",
    "        org = (50, 50)\n",
    "        fontScale = 1\n",
    "        color = (255, 0, 0)\n",
    "        thickness = 2\n",
    "        img = cv2.putText(img, prediction, org, font,\n",
    "                       fontScale, color, thickness, cv2.LINE_AA)\n",
    "\n",
    "        cv2.imshow('img', img)\n",
    "        # Stop if (Q) key is pressed\n",
    "        k = cv2.waitKey(30)\n",
    "        if k==ord(\"q\"):\n",
    "            break\n",
    "\n",
    "    # Release the VideoCapture object\n",
    "    cap.release()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
